[
  {
    "text": "ABSTRACT This study explores the use of generative AI (GenAI) and research integrity assessments of use cases by re- searchers, including PhD students, at Danish universities.\n\nConducted through a survey sent to all Danish re- searchers from January to February 2024, the study received 2534 responses and evaluated 32 GenAI use cases across five research phases: idea generation, research design, data collection, data analysis, and writing/ reporting.\n\nRespondents reported on their own and colleagues \u2019 GenAI usage.\n\nThey also assessed whether the practices in the use cases were considered good research practice.\n\nThrough an explorative factor analysis, we identified three clusters of perception: \"GenAI as a work horse\", \"GenAI as a language assistant only\", and \"GenAI as a research accelerator\".\n\nThe findings further show varied opinions on GenAI \u2019s research integrity implications.\n\nLanguage editing and data analysis were generally viewed positively, whereas experiment design and peer re- view tasks faced more criticism.\n\nControversial areas included image creation/modification and synthetic data, with comments highlighting the need for critical and reflexive use of GenAI.\n\nUsage differed by main research area, with technical and quantitative sciences reporting slightly higher usage and more positive assessments.\n\nJunior researchers used GenAI more than senior colleagues, while no significant gender differences were observed.\n\nThe study underscores the need for adaptable, discipline-specific guidelines for GenAI use in research, developed collaboratively with experts to align with diverse research practices and minimize ethical and prac- tical misalignment.\n\n1.Introduction Research employing Generative Artificial Intelligence (GenAI) is rapidly expanding across fields and is anticipated to accelerate and transform scientific knowledge [1].\n\nAs in many other parts of society, the integration of GenAI into academic research is characterised by a wide range of attitudes, perceptions, and yet to be developed practices.\n\nOwing to the inherent uncertainties that come along with new tech- nologies, fierce debates have emerged over the potential benefits, risks and challenges of using GenAI for research purposes (e.g.\n\nRef.\n\n[2,3]).\n\nAs the technology continues to reshape academic landscapes, understand - ing the adoption and impacts of GenAI in research practices becomes increasingly important.\n\nThe currently evolving discourse surrounding GenAI within academia reflects a spectrum of engagement ranging from enthusiastic adoption [4,5] to cautious valuation [6,7] and scepticism [8\u201310].\n\nFollowing an avalanche of opinion pieces and conceptual con- tributions, empirical studies offering valuable insights into GenAI \u2019s adoption, perceptions, and anticipated impacts across different schol - arly activities are currently emerging.\n\nStudies acknowledge GenAI \u2019s potential for efficiency gains and enhanced research processes, on one hand, while also revealing researchers \u2019 concerns about transparency, misinformation, biases, and generally unknown implications on the other [11].\n\nWhile existing research has provided a foundation for understanding the complexities of GenAI adoption, limited empirical work has sys- tematically explored its diverse use and perceptions across academic contexts and research fields.\n\nThis includes variations between disci- plines or ways of conducting research, as well as potential disparities *Corresponding author.\n\nDanish Centre for Studies in Research and Research Policy Aarhus University Bartholins All\u02d8e 7, 8000 Aarhus C, Denmark.\n\nE-mail address: jpa@ps.au.dk (J.P.\n\nAndersen).\n\nContents lists available at ScienceDirect Technology in Society u{\ufffd~zkw!\n\ns{yo| kro>!\n\n\u00d0\u00d0\u00d01ow \ufffdo\ufffdto~1m{y2w {mk\ufffdo2\ufffdoms\ufffd{ m https://doi.org/10.1016/j.techsoc.2025.102813 Received 10 September 2024; Received in revised form 12 November 2024; Accepted 7 January 2025 Technology in Society 81 (2025) 102813 Available online 9 January 2025 0160-791X/\u00a9 2025 The Authors.\n\nPublished by Elsevier Ltd.\n\nThis is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).\n\nacross career stages, gender and other demographics.\n\nFurthermore, question remain about not only whether, but how academics might use GenAI in research and how they assess its research integrity implications across various use cases.\n\nIndeed, research practices as diverse as plan- ning experiments, writing project proposals, generating and collecting data, analysing it, reporting it or transforming it into lay-accessible content can all potentially be assisted or conducted by GenAI tools.\n\nHowever, whether researchers actually do this and how they assess research integrity aspects of using GenAI for these various cases, remains largely unknown.\n\nWhile several actors are preparing policy interventions to steer the usage of GenAI in research (e.g., publishers, funders or research in- stitutions aiming to govern particular research practices, e.g.\n\nCommittee on Publication Ethics [12]), systematic understandings of researchers\u2019 own practices become increasingly important.\n\nIndeed, such policy ini- tiatives tend to remain paper tigers if not properly aligned with practices of those they tend to govern [13].\n\nThis paper aims to deepen our un- derstanding of GenAI\u2019s role in academia based on the results of a nationwide survey of researchers across Danish universities.\n\nBy exploring how researchers from diverse backgrounds, fields and schol - arly traditions use and assess the application of GenAI for a wide range of research tasks, this paper seeks to contribute to a more comprehensive understanding of GenAI\u2019s evolving role within academia.\n\nUltimately, this is intended to inform the preparation of tailored guidelines and models of accountability.\n\n1.1.\n\nOverview of other relevant studies In examining the current landscape of GenAI within academia, several studies have offered insights into its adoption, perceptions, and anticipated impacts across various scholarly activities.\n\nWhile most studies have focused on the use of GenAI in educational and teaching contexts, several have also examined research contexts.\n\nNotably, a sur- vey at a large U.S.\n\nresearch university revealed mixed attitudes among faculty and students towards GenAI, with a general openness to training despite low current usage and comfort levels, particularly in research contexts [14].\n\nContrastingly, a survey among higher education faculty reported a modest but growing integration of GenAI in research activ- ities, marking a 13-percentage point increase between spring and fall 2023 (9 % vs.\n\n22 %) [15].\n\nA survey among users of ResearchGate and Academia.edu found that reasons for researchers to use GenAI in their work are mainly related to timesaving, self-efficacy, self-esteem and reduction of stress.\n\nConversely, concerns over academic integrity and negative peer evaluations of GenAI usage, limit researchers\u2019 inclination to use GenAI tools for their work [16].\n\nAdditionally, several surveys were conducted in the context of the Nature portfolio of journals.\n\nA survey among authors of Nature articles and readers of Nature Briefing [11] found that while a large minority of researchers engaged with AI frequently, many expressed concerns about misinformation and biases, yet recognized benefits such as efficiency gains and improved accessibility for non-native English speakers.\n\nAnother survey conducted by Nature among 3838 postdocs indicated similar level of engagement with GenAI, particularly chatbots, with 31 % of respondents reporting using chatbots.\n\nInterestingly, a majority (67 %) felt AI had not significantly altered their day-to-day work or career plans [17].\n\nSimilarly, a survey among readers of the Nature journal suggested a diversely engaging but cautious approach towards GenAI in academia [18].\n\nOut of the 40 % that used GenAI at least occasionally, most report using it for coding tasks or to help write manuscripts, pre- pare presentations or conduct literature reviews.\n\nFurthering this discourse, findings from a UK-based survey high- lighted that over half of the academics utilized GenAI for efficiency, expecting its role to expand significantly [19].\n\nThis sentiment mirrors the European Research Council\u2019s [20] survey results, which anticipated AI (not necessarily generative AI) fostering faster academic processes and enhancing human-AI collaborations, albeit with concerns about potential ethical and transparency issues.\n\nApart from this host of survey studies on researchers\u2019 use and per- ceptions of GenAI, two other empirical studies are worth mentioning here.\n\nA systematic review of the literature on guidelines and standards on how to use GenAI and Large Language Models (LLMs) in academic medicine [21] came to five recommendations for which they feel there is sufficient consensus among the research community, including state- ments like Chatbots not being allowed as an author in scientific manu - scripts; humans must be held accountable for use of ChatGPT/LLM and contents created by ChatGPT/LLM should be meticulously verified by humans.\n\nThe study highlights the necessity for robust guidelines to govern GenAI\u2019s academic use, advocating for accountability in AI-generated content.\n\nThis need for clarity and oversight is crucial as evidenced by Gray\u2019s [22] quantitative analysis, which discovered a noticeable uptick in LLM-assisted publications within engineering and natural sciences \u2013 a trend that highlights the differential adoption rates across disciplines.\n\nGray estimates that up to 85,000 LLM-assisted articles were published in 2023, indicating significant adoption of GenAI in academic publishing, for which other papers have provided (more anecdotal) evidence too.\n\nWe note that the literature of studies examining GenAI use in the research process is likewise quickly developing and any overview will inevitably only provide a snapshot of the current state of affairs.\n\nApart from empirical work on the adoption, perceptions and impli - cations of GenAI in research contexts, the ethical implications of this new technology have been hotly debated.\n\nMultiple ethical principles in question have been highlighted and based on a literature review, Ning et al.\n\n[23] identified nine key principles to be used to build an ethical framework for GenAI use in health care: accountability, autonomy, eq- uity, integrity, non-maleficence, privacy, security, transparency, and trust.\n\nThese nine ethical dimensions are all related to broader ethical principles such as honesty (related to integrity) and fairness (related to equity).\n\nNing et al.\n\n[23] use them to form a check list called \u201cTrans - parent Reporting of Ethics for Generative AI (TREGAI)\u201d that can be used to strengthen ethical considerations on the use of GenAI within health care and beyond.\n\nWhile these principles relate to the use of GenAI in multiple contexts, its use for research purposes raises additional ques- tions, for example related to authorship issues [24], copyright and in- tellectual property [25], and reproducibility and open science [24].\n\nWhile many have called for swift actions in terms of improved ethical guidance and regulations (e.g.\n\nRef.\n\n[26]), others acknowledge the fast-moving nature of this technology and the implication that any regulation is doomed to become outdated or obsolete soon after its development.\n\nBased on a Delphi process involving a panel of scholars from the social sciences, law, ethics, and scientific publishing, re- searchers co-created a set of core principles informing the responsible use of GenAI in research.\n\nThis approach aims to allow flexible use under conditions of diverse technological developments and stipulates re- searchers to adhere to (principles of) regulation, data security, quality control, originality, bias mitigation, accountability, transparency and wider impact [27].\n\nThe latter notably also included social and climate justice.\n\n1.2.\n\nResearch objective and questions The empirical studies mentioned above collectively indicate an evolving uptake of GenAI technologies in the academic community.\n\nThe insights reflect a spectrum of engagement, from enthusiastic adoption to fierce scepticism, which is still in flux.\n\nThis evolution is evident in the significantly different results observed in subsequent waves of similar surveys.\n\nHowever, up to this point, studies have suggested some varia - tions but have failed to systematically examine the diversity of GenAI use and perceptions across academic contexts.\n\nThis includes variations between disciplines or ways of doing research, as well as potential variations across career stages and other demographics.\n\nIn addition, J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 2 relatively little is known about how academics use GenAI in their work and how they assess the research integrity of different GenAI practices, if they think of them as good or bad research practices.\n\nIn this study, we aim to address these knowledge gaps by conducting a nation-wide survey of researchers at Danish universities.\n\nWe examine how researchers from various backgrounds and scholarly traditions use and assess the use of GenAI for a wide range of research tasks.\n\nIn the remainder of this article, we will report the results of this survey and reflect on the implications for regulating GenAI use for research pur- poses.\n\nOur article will be guided by two research questions.\n\n1.\n\nFor what purposes and to what extent is GenAI applied for research at Danish universities by researchers across different disciplines/ research fields, career stages and demographics?\n\n2.\n\nWhat are the overall research integrity assessments of researchers towards the integration of GenAI in academic research?\n\nHow do attitudes towards GenAI vary across different scientific fields, career stages, and demographics (e.g., gender, seniority)?\n\n2.Methods A description of the survey, the sampling process and analysis plan were described prior to launching the survey and uploaded to OSF [37].\n\n2.1.\n\nStudy participants The survey was fielded as a census of all researchers at Danish uni- versities.\n\nPrevious studies have indicated that research practices and ways of producing knowledge, as well as researchers\u2019 assessment of good and bad research practices, strongly differ between researchers from different research backgrounds, demographics and institutional contexts [28].\n\nTherefore, we aimed to reach researchers from all main areas of research.\n\nAs the accessibility and legal framework impacting the use of novel technologies and generative AI in particular, differs across national contexts [29], we decided to field our survey in a single country, in order to minimize variation in this respect.\n\nTogether, these considerations resulted in our choice of including all researchers including PhD students at Danish universities as our participants.\n\nPar- ticipants were sampled by collecting contact details from the institu - tional personal webpages of the researchers.\n\nA script was written to automatically collect the email addresses of all research staff of Danish universities.\n\nThis resulted in 50,652 people with contact details and job titles.\n\nAs we were only interested in staff members with research tasks, we selected all job titles that occurred at least 50 times (118 job titles) and suggested an academic position that might involve research tasks (leaving 88 different job titles).\n\nThis resulted in 30,590 people.\n\nRemoving duplicates (e.g.\n\nresearchers working at multiple departments, hence having multiple email addresses) and inactive email addresses, the survey was sent out to 29,498 researchers including PhD students at Danish universities on Jan 22nd, 2024.\n\nTwo reminders were sent to researchers who had not fully completed the survey and had not opted out of receiving further communication about it.\n\nThese waves of in- vitations were sent to 27,978 and 26,670 researchers respectively.\n\nBefore starting the survey, participants were asked to confirm that they are: \u201can active researcher at a Danish university holding a PhD degree (or equivalent)\u201d or are \u201ca PhD student\u201d.\n\nPrior to sending out the full survey, 200 researchers were randomly selected from our sample to conduct a pilot survey.\n\nThey received the full survey, with the additional request to flag any mistakes or phrases that were unclear.\n\nThis led to minor adjustments of the survey instrument.\n\nAfter concluding the survey, identifying information that had been used to contact respondents was removed, without links to other data sources.\n\nAll analyses were done on this data set.\n\nThe qualitative re- sponses were further reviewed to remove potentially identifying infor- mation from the published data set.2.2.\n\nSurvey instrument and respondents The full survey instrument can be found on the project\u2019s OSF page [37].\n\nThe survey consisted of two phases.\n\nIn the first phase, we collected demographic and other background variables on the participants, including gender, academic age, native language, academic field and knowledge production ways (e.g.\n\nquantitative or qualitative social sci- ences, theoretical or experimental natural science, etc.), participants\u2019 exposure to institutional regulations and conversations about AI, and the extent to which they use GenAI either professionally or personally.\n\nIn the second phase, participants were presented with 32 potential use cases of AI, divided into five research phases (see Table 1).\n\nFor each use case, they were asked to consider if they had recently used AI for this purpose, if they were aware of colleagues with whom they had collab - orated over the last year who had done so, and whether they considered the use case to be a good or problematic research practice.\n\nThe survey concluded with two open questions asking respondents whether they had one or multiple specific GenAI tools in mind when completing the survey and providing them the opportunity to leave any additional comments they wanted to share.\n\nOut of the 29,498 invitations, we received 2534 complete responses (8.6 %), with another 533 respondents answering part of the questions (1.8 %).\n\nTable 1\u2013 table supplements 1\u20134 present an overview of the survey respondents and their self-reported demographic and disci- plinary backgrounds.\n\nIt also compares respondents\u2019 characteristics with Table 1 Overview of use cases per research phase.\n\nID column shows the codes used in the analyses, corresponding to the use cases.\n\nPhase Use case ID Idea Generation help identify gaps in current research idea1 help identify relevant literature idea2 help summarize or analyse existing literature idea3 help identify potential collaborators idea4 help propose new hypotheses idea5 Research Design suggest a structure for research proposals rd1 help draft parts of a research proposal rd2 refine or edit language of research proposals rd3 refine or edit content of research proposals rd4 help design research methodology rd5 help develop theoretical models or conceptual frameworksrd6 help design experiments rd7 Data Collection suggest experimental parameters dc1 help formulate questions for surveys or interviews dc2 generate synthetic data sets dc3 transcribe recordings of research material (e.g.\n\ninterviews, workshops or focus groups).dc4 identify ethical issues in research (either your own or someone else\u2019s)dc5 Data Analysis create or edit software code for data analysis da1 create or edit simulation software code da2 support statistical data analysis da3 help pattern recognition in data da4 create or modify scientific figures or images da5 Writing and Reportingsuggest a structure for a research article pub1 help draft parts of a research article pub2 propose a title, abstract or keywords for your article pub3 edit a research article to improve readability and/or languagepub4 format references pub5 identify strengths and weaknesses in a manuscript during the peer review processpub6 help write review reports during the peer review processpub7 translate one of your research papers into a different languagepub8 help create (parts of) a slide deck for a conference talk or similar academic eventpub9 help create lay summaries or similar non-academic writing for public engagement, based on your own textspub10J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 3 the full study population in terms of gender and disciplinary back- ground.\n\nGender of the non-respondents was inferred using first names and disciplinary background was inferred from non-respondents\u2019 departmental affiliation.\n\n2.3.\n\nDescription of quantitative analyses All quantitative analyses were performed using R version 4.3.2.\n\nMultiple imputation was done using the \u2018mice\u2019 package [30].\n\nThe categorical academic age variable was constructed from a binary response on whether the respondent was a current PhD student, and a year for when the PhD-degree was awarded.\n\nWe recoded these years to roughly correspond to the categories of European Research Council grant levels, so that respondents with a PhD from after 2016 are \u201cstarting\u201d, those with a PhD before 2017 and after 2010 are \u201cconsoli - dators\u201d and those with a PhD from before 2011 are \u201cadvanced\u201d.\n\nFor the purpose of calculating aggregated scores and imputing missing values, we also created recoded versions of all numerical values of responses to personal use and the use of others, so that the responses \u201cNo\u201d and \u201cNot relevant for me\u201d were recoded to 0, \u201cYes\u201d to 1, and \u201cDon\u2019t know\u201d to missing value.\n\nResearch integrity assessments were recoded for readability purposes only, as the value 1 corresponded to \u201cexcellent\u201d and 7 to \u201cvery problematic\u201d.\n\nWe reversed this scale and converted the value 8 (\u201cUnable to answer\u201d) to missing values.\n\nThe multiple imputation was done in two batches, one for the two usage groups of variables, and one for the research integrity assessment variables.\n\nAs the usage variables are binary, we used logistic regression, while we used predictive mean matching for the assessments.\n\nBoth batches ran through 20 iterations.\n\nThe imputed data are used for both the reported aggregate scores and the factor analysis.\n\nAggregated use scores are the mean use of an indi- vidual respondents, and corresponds to the proportion of use cases, the respondent has said \u201cyes\u201d to using GenAI for.\n\nThe aggregated research integrity assessment is the mean value of these assessments, ranging from 1 (all use cases are rated very problematic) to 7 (all use cases are rated excellent).\n\nFactor analysis was done using the \u2018psych\u2019 package in R [31].\n\nWe used parallel analysis to identify three factors with an eigenvalue above 1.\n\nWe use a maximum likelihood factoring method with varimax rota- tion, to select factors with distinct peak loadings.\n\nThe resulting loadings are high, with several peaks above .6, and 49.1 % of the variance explained.\n\nWhile the explained variance is not exceptional, we still consider it reasonable.\n\nAdding two additional factors would only explain 5.7 % more of the variance, which would not be justifiable, and intro- duce noisy factors.\n\nUsing the individual factor scores per observation, we cluster ob- servations with k-means clustering with three centres, equivalent to the number of factors.\n\nHierarchical clustering visually supports the number of clusters.\n\nThese clusters group respondents while the factor loadings group the variables.\n\n2.4.\n\nDescription of qualitative analyses The qualitative data we utilized was gathered from two open-text field questions included in the survey.\n\nThe first question asked re- spondents about the types of GenAI tools they used, and the second, broader question sought their comments or insights related to using GenAI for research purposes.\n\nThe responses to the first question were compiled and visualized in bar graphs, segmented by gender, PhD age, research field, and whether the researchers were mono-disciplinary or multidisciplinary (Fig.\n\n2- figure supplements 1\u20135).\n\nAs for the second question, we received a total of 543 comments (excluding responses that indicated \u2018no comment\u2019).\n\nTo analyse the comments, we categorized the responses into emerging thematic groups: \u2019No comment\u2019, \u2019Understanding of the survey or elaboration of answers\u2019, \u2019Assessment of good or bad practice\u2019, \u2019Description of GenAI as a tool\u2019, \u2019Thoughts or issues related to policy, training, or infrastructure for GenAI\u2019, \u2019Examples of use\u2019, and \u2019General opinions or emotions about GenAI\u2019.\n\nThe comments and coding results can be found on the project\u2019s OSF site [37].\n\nHere, we have removed any identifying information from the open text fields, including names, university details, department or specific research fields, and any particular activities mentioned by re- spondents that could lead to identification.\n\nTo help us analyse the three clusters identified in this paper, we specifically focused on the 182 comments coded under \u2019Assessment of good or bad practice\u2019.\n\n3.Results The purpose of this initial study has been to document the use of GenAI and research integrity assessments among researchers.\n\nIt is therefore primarily descriptive, focused on gathering data and reporting and discussing evidence.\n\nThe collection of literature informing the study provided an overview of the most present empirical research evidence in this fast-developing topic area.\n\nThe potential key characteristics and factors for the use of GenAI and research integrity assessments among researchers were identified, operationalized, included, and measured in the study\u2019s data collection as reported in section two and this section.\n\nThe study does not delve into potential causal factors behind differing perceptions of GenAI use, as this would require additional, nonstruc - tured data, i.e.\n\ninterviews which have not yet been collected.\n\n3.1.\n\nDescriptive overview of main results The survey was launched on January 22, 2024, and remained open until February 26, 2024, with one invitation and two reminders being sent to all researchers (incl.\n\nPhD students) of all eight Danish univer - sities.\n\nOut of the 29,498 invitations, we received 2534 complete re- sponses (8.6 %), with another 533 respondents answering part of the questions (1.8 %).\n\nIn the analyses below, we only use the complete re- sponses.\n\nThe survey consisted of two main parts, one with questions regarding general GenAI experience and demographic background variables, the other presenting 32 use cases across five phases of research work (Table 1).\n\nFor each use case, respondents were asked about their own use, the perceived use of others, and an assessment of the use case in terms of research integrity on a 7-point Likert scale from excellent research practice to very problematic research practice.\n\nFurther details about the survey can be found in the methods section.\n\nRespondents were generally well spread across disciplinary back- grounds and demographics.\n\nWe refer to Supplementary Table 1-Sup- plementary Table 4for a descriptive overview of respondents\u2019 background and demographics relative to the study population.\n\nIn this section, we present descriptive statistics on the use and research integrity assessment of the 32 cases of GenAI use in the research process.\n\nFig.\n\n1presents a plot of the research integrity assessment and average use (both own use and the perceived use of colleagues) of each of the individual use cases.\n\nIt shows a rather wide distribution of research integrity assessments for most use cases, indicating diverse opinions about whether using GenAI tools for these purposes constitutes problematic or good research practices.\n\nIn general, respondents assessed using GenAI for language editing use cases (e.g.\n\nin proposal writing, editing of research articles, formatting references) and those related to data analysis (e.g.\n\ncreating codes for analysis or simulation, pattern recognition, transcription of research recordings) as rather good research practices.\n\nIn contrast, usage of GenAI for arguably more fundamental tasks related to designing research experiments or theo- retical frameworks and critical assessment of other work during peer review was considered more problematic.\n\nTwo use cases that were particularly contentious were those related to the creation or modification of images and figures, and the creation of synthetic data.\n\nBoth these cases might have different connotations in diverse research fields.\n\nAn important observation in relation to the J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 4 research integrity assessment is that many respondents elaborate in the open text field of the survey [37], that their integrity assessment of the use of GenAI depends on it being used critically and reflexively.\n\nAs one respondent puts it: \u201cAlthough I have answered in many cases that using AI is excellent practice, this does not mean that it should be used uncritically or without checking references etc.\n\nI just consider AI as giving an excellent head start on all of these tasks \u201d (ID19826) .\n\nThe qualitative comments, allowing respondents to contextualise their responses, contain several descriptions indicating a lack of trust in GenAI.\n\nThe main problems mentioned are hallucination (that the chat- bot \u201cmakes up\u201d information), violation of privacy rights and copyrights (not knowing what is allowed to be fed into e.g.\n\nGenAI tools), potential biases, and \u2019black boxing \u2019 of the generative process.\n\nGenerally, we observe a moderate positive correlation between the research integrity assessment of use cases and their admitted use by respondents (Kendall \u2019s \u03c4 \u0088.44) or their colleagues (\u03c4 \u0088.5).\n\nSome ex- ceptions are the use of GenAI to identify potential collaborators and to create synthetic datasets (relatively low use), and to propose a title, keyword or abstract or even help draft parts of the body of an article (with relatively high admitted use).\n\nFor all use cases, the reported use of GenAI of direct colleagues is higher than that of respondents themselves, with particularly large relative differences for the two use cases related to the peer review process (identifying strengths and weaknesses of manuscripts under review and writing review reports).\n\nThis is in line with what is found in other surveys, e.g.\n\nfocusing on questionable research practices and malpractice [32].\n\nLast, we note that for almost all use cases, the share of respondents indicating a use case to be a good, very good or excellent practice is higher than the share of respondents indicating to have used GenAI for this purpose.\n\nThis suggests that, while reported use of GenAI is still fairly low, the reason for not engaging in more use cases of GenAI is probably not primarily related to research integrity considerations.This is further underlined by aggregated assessment and usage scores (see Supplementary Fig.\n\n1), illustrating higher assessment scores, and lower variance, as usage grows.\n\nRespondents that had not used GenAI, or only had used it in very few use cases, had much higher disagreement on the assessment of the use cases on average.\n\nFig.\n\n2presents the aggregated use and research integrity assessment of all 32 use cases, broken down by research field (top panel), knowl - edge production ways (second panel), gender (third panel) and aca- demic age (bottom panel).\n\nIt shows relative consistency in responses across main research areas, with most users in all disciplines indicating to use GenAI tools for only few use cases.\n\nHowever, a somewhat larger proportion of respondents from the technical sciences, especially those in the experimental technical sciences, indicate to use GenAI for a higher number of different use cases, some even for more than half of all use cases mentioned in our survey.\n\nSimultaneously, respondents from the technical sciences have the highest aggregated research integrity assessment of our 32 use cases.\n\nIn contrast, scholars from the humanities indicate to use GenAI tools least frequently and they also have the least positive research integrity assessment of the use of GenAI for research purposes.\n\nSome of the respondents from this main area of research indicate to have a strongly negative research integrity assessment of the usage of such tools for many use cases.\n\nA substantial share of re- spondents from the humanities (19.3 %) gives an overall assessment of 3 or less on a 7-point scale (i.e.\n\ndegrees of \u2018problematic research practice \u2019).\n\nLooking at differences within research fields, we note that quanti - tative social scientists indicate to use GenAI tools for substantially more use cases than their colleagues from the qualitative social sciences.\n\nAgain, we notice the inverse pattern in terms of research integrity assessment, i.e.\n\nthe qualitative social scientists giving slightly lower scores to the acceptability of using GenAI tools for various purposes.\n\nIn terms of gender, no differences in either use nor ethical assessment were observed between men and women.\n\nSome variations are reported in the other two categories (non-binary and \u2018do not wish to disclose \u2019), but these contain only few observations.\n\nFig.\n\n1.Research integrity assessment scores and share of participants using GenAI for specific use cases .\n\nResults are shown by research phase.\n\nBrown bars show the shares of respondents judging the use case as a problematic practice, while green bars show positive assessments.\n\nLight gray bars are the share of neutral responses.\n\nBlue dots in the right panel show how large a share of respondents that report ever having used AI for the specific use case, while yellow dots show the share of respondents who report that they believe their colleagues use AI for this use case.\n\nHorizontal lines in the right panel serve as visual guides only.J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 5 In terms of academic age, we observe a clear pattern in usage of GenAI tools, with more junior scholars using GenAI for more different purposes than their senior colleagues.\n\nIn terms of research integrity assessment, no substantial differences between respondents from different academic ages were observed.\n\nThis means junior scholars have been quicker to adopt GenAI tools for various use cases than their senior colleagues, even with similar assessment of the appropriateness of such usage.\n\nIf we look at the GenAI tools that respondents had in mind when answering the survey, most respondents indicated to be thinking of ChatGPT (n \u00881550), while 894 respondents answered \u2018no\u2019 or did not answer the question about if they had any specific tools in mind while answering the survey (Fig.\n\n2\u2013 figure supplement 1).\n\nCopilot (both Microsoft and GitHub) was the second most mentioned tool (n \u0088176).\n\nOther tools mentioned include Grammarly (n \u0088101), Google \u2019s Bard (n \u008876), Dall-E (n \u008874) and DeepL (n \u008869).\n\n3.2.\n\nFactor analysis We used exploratory factor analysis to identify patterns in the vari- ance of research integrity assessments.\n\nWe identified three clusters, supported by the eigenvalues in the parallel analysis (Supplementary Fig.\n\n2.Distribution of aggregated use and research integrity assessment scores .\n\nEach panel shows the aggregated research integrity assessment (left column) or aggregated use (right column) across research field, knowledge production ways, gender and academic age (top to bottom).\n\nColours in knowledge production ways distributions correspond to colours in research field.J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 6 Fig.\n\n7).\n\nWe also checked the correspondence between observed and multiply imputed responses (Supplementary Fig.\n\n8) and consider the correspondence sufficient to incorporate imputed responses for a more complete data material.\n\nFactor loadings underlying the cluster analysis are available in Supplementary Fig.\n\n9.\n\nThe factor analysis revealed three clusters of research integrity assessment of GenAI use cases among respondents (Fig.\n\n3), based on a k- means clustering of individual factor scores.\n\nThe clusters differentiate from each other by highlighting different types of integrity assessments of GenAI use in research.\n\nCluster 1 could be labelled \u201cGenAI as a work horse \u201d, with 893 respondents (35.2 %).\n\nIn this cluster we find re- searchers who consider using GenAI to create and edit software codes for analysis and simulation (da1-2), to support statistical analysis (da3) and to help recognize patterns in data (da4) as good research practices.\n\nOn the other hand, researchers in this cluster are more sceptical towards using GenAI in the peer review process (cf.\n\npub6 and pub7) than re- searchers in the two other clusters.\n\nThey also score using GenAI in the \u2018Idea generation phase \u2019 (idea1-5) lower than researchers in the other two clusters.\n\nIf we look at the comments from researchers in this cluster, made in the open text field in the survey [37], some researchers, point out that GenAI \u201cis good when used for tedious tasks like formatting, editing, generating a code for idea that you have in mind, generating drafts, etc, and terrible for creative tasks \u201d (ID2561), that it is \u201cproblematic to be using generative AI in creating articles or other written materials \u201d (ID13760) , but that GenAI can be good for \u201cchecking language and reviewing code \u201d (ID12608) .\n\nThis cluster is thereby mainly characterised by using GenAI as a tool to speed up, process, or help researchers with technical issues in relation to their research \u2013 i.e.\n\nas a \u201cwork horse \u201d.\n\nIn cluster 2 \u2013 tentatively called \u201cGenAI as a language assistant only \u201d, we find the most sceptical respondents (n \u0088609, 24.0 %).\n\nThey generally assess the use of GenAI more negatively than the other clus- ters, but it is also in this cluster where we find the most \u201cneutral \u201d re- sponses.\n\nPositive assessments are mainly found for use cases related to language editing, e.g.\n\nrefine and edit language of research proposals (rd3), transcribe recordings of research material (dc4) and propose ti- tles, keywords, or abstracts, edit research articles for readability and formatting references (pub3-5).\n\nParticularly, cluster 2 researchers find it more problematic to use GenAI for data analysis (da1-5) than re- searchers in the other two clusters.\n\nIn the open text field comments from cluster 2, researchers provide some clarification of this pattern.\n\nRe- spondents referred to GenAI as \u201ca glorified spell checker \u201d (23440), and mentioned that it is potentially useful \u201c[n]ot so much in actual research, but for various kinds of help-services, especially in connections with language polishing/translation and editing \u201d (20622) .\n\nOverall, it seems that re- searchers in this cluster are generally sceptical towards using GenAI for research purposes, potentially with the sole exceptions of using GenAI as an assistant in the more \u201clanguage related \u201d aspects of the research process.\n\nThe positive assessments are very few and weak in this cluster.\n\nFinally, in cluster 3, which could be labelled \u201cGenAI as a research accelerator \u201d, we find 1032 researchers (40.7 %) who are generally very positive in their assessment of GenAI.\n\nThey are positive about using GenAI in almost all use cases, particularly in relation to data analysis and research design.\n\nThere are only a few use cases with a slightly more varied/negative assessment, e.g.\n\nthe creation of synthetic datasets (dc3) and identifying ethical issues in research (dc5).\n\nAgain, the comments do not directly explain why the researchers in this cluster score these use cases as they do.\n\nThe comments deal with many different issues, but some researchers mention that using GenAI tools help them become more productive: \u201cI do believe that AI is excellent practice for increasing productivity especially in the form of content/outline SUGGESTION (not copy-pasting it for the final version of a paper as content might be faulty and is often too general), language improvement (here AI is excellent and I don\u2019t see any ethical/moral problems with it as long as input data is not confidential), and generating first drafts of sections based on my own (unstructured) content/thoughts (again, I do not see any problem with that as the content still comes from me).\n\n\u201d (ID20164) .\n\nIn terms of reported use, all three clusters follow a similar pattern regarding the use cases for which higher/lower use of GenAI is self- reported.\n\nThe clusters only differentiate in the extent to which they report higher/lower use, with respondents in cluster 3 consistently reporting highest use for every use case.\n\nHence, while we observe relatively strong differences in terms of research integrity assessment, Fig.\n\n3.Research integrity assessment responses and own use across all use cases, split by factor loading clusters .J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 7 these only weakly reflect in respondents \u2019 self-reported use of GenAI across different clusters.\n\nIf we look at the demographic distribution of respondents over the three identified clusters (Fig.\n\n4), we do not find any differences in how men and women assess the research integrity of different GenAI use cases.\n\nSimilarly, there are only minor differences in how different seniority groups (PhD students, and starting, consolidated and advanced researchers) assess what is good use of GenAI.\n\nOnly in relation to main areas of research and knowledge production ways, we find more pro- nounced differences.\n\nIn cluster 1 \u2013 \u201cGenAI as a work horse \u201d \u2013 we find researchers from all types of epistemic backgrounds.\n\nHowever, researchers from the hu- manities, who work on data produced by themselves (26.4 %), clinical medical researchers (30.5 %), and theoretical natural scientists (31.7 %) are less well represented in this cluster compared to researchers working with other ways of producing knowledge, who have a representation of between 34.1 % and 40 % in cluster 1.\n\nIn cluster 2 \u2013 \u201cGenAI as a language assistant only \u201d \u2013 we find a bigger proportion of humanities scholars (36.6 %) compared to the other four main areas of research (from 20.6 to 23.4 %).\n\nIf we look at differences between researchers using different knowledge production ways, we similarly see that a greater proportion of the humanities scholars, who work on data produced by themselves, are to be found in cluster 2 (41.5 %), compared to the other nine knowledge production ways.\n\nHowever, many theoretical natural scientists (32.1 %), humanities scholars working on existing data (30.4 %), and qualitative social scientists (29.9 %) can also be found in this cluster of GenAI sceptics.\n\nWhereas, in comparison, much fewer quantitative social scientists (13.8 %), exper - imental natural scientists (17.8 %), basic medical scientists (19 %) and experimental technical scientists (19.3 %) are represented in this cluster.\n\nIn cluster 3 \u2013 \u201cGenAI as a research accelerator \u201d \u2013 we find a smaller proportion of researchers from the humanities (32.9 %) compared to the other main areas of research.\n\nFor example, in the technical sciences, 44.1 % of researchers belong to this cluster, and in medicine it is 42.9 %.\n\nIf we look at the 10 different knowledge production ways, the human - ities scholars are joined by the qualitative social scientists (33.3 %) and Fig.\n\n4.Demographic distribution of respondents over factor clusters.\n\nEach heatmap shows the distribution of research age, gender, knowledge production way and research field for the three clusters of observations identified in the factor analysis.J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 8 the theoretical natural scientists (36.2 %) in being proportionally less represented in this cluster compared to other knowledge production ways.\n\n4.Discussion In this study, we set out to explore the use and assessment of GenAI in various research practices across gender, seniority, main areas of research, and knowledge production ways.\n\nThe results show that there were no or only very minor differences in the use and assessment in relation to gender.\n\nSome variations were found related to seniority and bigger differences were found related to the different main areas of research.\n\nAs Fig.\n\n2shows, both the patterns of use and assessment are fairly similar within and across main areas of research.\n\nAn interesting finding of the study, which nuances these minor dif- ferences, is that we find the largest disagreement of how to assess the research integrity of particular use cases \u2013 how good a practice they are perceived to be \u2013 in the group of the non- or infrequent users.\n\nThis means that the agreement in assessment increases with use and indicates that familiarity with GenAI leads to similar, usually more positive, evalua - tions.\n\nThis points to a need for more training for researchers within all fields; a need which is also echoed in a number of the qualitative com- ments to the survey.\n\nThis difference in use \u2013 that some use GenAI more than others \u2013 is further highlighted in the factor analysis presented above, where three main clusters of GenAI users in Danish academia are identified: \u201cGenAI as a work horse\u201d, \u201cGenAI as language assistant only\u201d, and \u201cGenAI as a research accelerator\u201d.\n\nInterestingly, the use patterns across the clusters are remarkably similar, but the degree of use differs.\n\nThis means that the researchers in the three clusters use (and do not use) GenAI for the same things, but to a varied degree.\n\nWe also observe a moderately positive correlation between research integrity assessment of use cases and re- ported use of the same cases.\n\nOur data do not allow identification of the direction of causality (i.e.\n\nwhether more use creates a more positive view of GenAI or the other way around).\n\nNevertheless, this correlation is fairly weak, and many respondents report positive assessments of use cases but no actual use of them.\n\nThis suggests that non-use is often re- ported not because of research integrity concerns but due to other rea- sons, such as lack of awareness that GenAI can be used for this purpose, insufficient skills on how to use GenAI or a lack of confidence that peers will approve of GenAI usage and concerns about potential negative consequences.\n\nHowever, the factor analysis also reveals some interesting differ - ences between disciplines and different ways of producing knowledge across the three clusters.\n\nThese differences are most pronounced in \u201cGenAI as a research accelerator\u201d (Cluster 3) and in Cluster 2, \u201cGenAI as a language assistant only\u201d.\n\nIn Cluster 3, the most GenAI-positive group, we find mostly researchers from the technical and medical sciences, as well as quantitative social scientists and experimental natural scientists.\n\nIn Cluster 2, on the other hand, we have more researchers from the humanities, qualitative social science, and theoretical natural science compared to other knowledge production ways.\n\nThis pattern might reflect important differences in the way in which knowledge is pro- duced; in the methods used and the overall approach to doing research, including the normative frameworks associated with these diverse ap- proaches to knowledge production.\n\nThis difference can be described as a difference between nomothetic and ideographic research areas ([33] [1894]) \u2013 or perhaps more pre- cisely, between more positivist ways of doing research, on the one side, and interpretative approaches on the other side.\n\nIt seems clear that the more interpretivist researchers are more sceptical towards GenAI, and that they also use the \u201cneutral\u201d option more than the other clusters.\n\nThis may be because use cases are seen as irrelevant to their research approach, e.g.\n\ngenerating hypotheses or suggesting experimental parameters.\n\nOur study also demonstrates the complex interplay between regulations and community norms in shaping responsible GenAI use.\n\nWhile top-down regulations can provide a clear framework for good research practices, their effectiveness is contingent on their alignment with the values and practices of the research community.\n\nThe case of peer review exemplifies this dynamic.\n\nIt is among the few use cases surveyed in our study for which clear guidelines exist, prohibiting the use of GenAI for this purpose [34].\n\nSimultaneously, we observe that this use case is among those with the strongest moral objections, perhaps influenced by the guidelines themselves.\n\nHowever, it is equally plausible that the guidelines were formulated in response to perceived pre-existing community concerns.\n\nThis interplay highlights the need for a balanced approach to regulating GenAI in research.\n\nWhile top-down frameworks may help shape standards, rigid, top-down frameworks that disregard community norms risk being ineffective or even coun- terproductive [35].\n\nConversely, a purely bottom-up approach may lead to inconsistent practices and tensions between diverse research areas.\n\nIn addition, our respondents indicate a clear desire for more support from their institutions (e.g.\n\ntraining and access to relevant infrastructure), to allow for well-considered and responsible use of GenAI for research purposes.\n\nThe latter touches on the wider ethical considerations of using GenAI for research purposes.\n\nAs outlined by others, GenAI poses various ethical challenges to researchers [27].\n\nOur survey adopted relatively inclusive terms to refer to such ethical considerations when asking for re- spondents\u2019 assessments.\n\nWe used the language of \u2018responsible research practices\u2019 in relation to specific research tasks, thereby likely triggering assessments of ethical aspects most closely related to integrity and pri- vacy [23].\n\nIn their responses to the open questions, some of our re- spondents nevertheless referred to wider ethical principles including those of equity, fairness and accountability.\n\nThe broader impact of using GenAI, including issues such as social and climate justice and referred to as the final principle in Knoechel et al.\n\n[27] framework for responsible GenAI usage, were hardly explicitly touched upon by our respondents though.\n\nIn contrast, issues such as accuracy, trustworthiness and privacy were omnipresent in our respondents\u2019 comments.\n\nThis aligns well with calls for regulation noted by ethicists Resnik and Hosseini [36].\n\n4.1.\n\nLimitations While our study provides valuable insights into the use and assess - ment of research integrity of GenAI in the research process across various research fields in the Danish university context, it is important to acknowledge a number of limitations that may influence the interpre - tation of the findings and their generalizability.\n\nFirst, there might be different interpretations among survey partici - pants of what constitutes a GenAI tool.\n\nWhile many researchers thought about tools like ChatGPT when filling in the survey, others had more general tools in mind like Grammarly.\n\nOther researchers note that they had highly specialized tools in mind, developed for particular research tasks.\n\nThis variation can influence the reported use and research integ - rity assessments of the tools.\n\nSimilar considerations might have affected the interpretation of use cases, which might have different connotations within different knowledge production ways and epistemic cultures (e.g.\n\nthe creation of \u2018synthetic data\u2019).\n\nSecond, the study is based on responses from a specific subset of Danish university researchers.\n\nThe sample may not be fully represen - tative of the entire Danish academic community, considering potential biases in who chose to participate in the survey.\n\nThe low number of respondents in certain categories, e.g., non-binary and \u201cdo not wish to disclose gender\u201d options, also constraints the ability to draw any con- clusions for these specific groups.\n\nMoreover, respondents might under - report or overreport the use of GenAI tools and their research integrity assessments due to personal beliefs or perceived expectations.\n\nResearch integrity assessments are subjective and vary based on individual values, backgrounds, and disciplinary/field norms [22].\n\nThis diversity may lead to a wide range of integrity assessments for similar use cases.\n\nThe J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 9 distribution of research integrity assessments indicates that there are many different opinions on GenAI use, which might be influenced by individual skills and experiences, field and disciplinary standards, and personal ethics.\n\nSocial desirability might, for example, have played a role in how researchers have answered.\n\nThird, the field of GenAI is evolving fast, and tools and their appli - cations can change drastically over short periods.\n\nNew tools emerge and existing ones are updated, potentially changing use patterns and research integrity perceptions.\n\nTherefore, our findings should be considered a snapshot of the state of affairs at a specific time and context, not necessarily generalizable to other settings.\n\nFourth, our study does not extensively explore the influence of cul- tural and institutional factors on the use of GenAI tools and research integrity assessment of use cases.\n\nUniversities may have different pol- icies and support structures that impact on how researchers engage with the tools.\n\nFinally, while we studied a broad array of GenAI use cases, there are obviously other potential applications of GenAI in research that were not covered in our research.\n\nFuture studies could expand the range of GenAI tools and use cases to provide a more comprehensive picture.\n\n5.Conclusion and implications Based on an initial collection of empirical evidence on the use of GenAI and research integrity assessments among researchers, this study has addressed pressing issues regarding GenAI\u2019s application, percep - tions, and ethical dilemmas in research.\n\nThis provides a necessary base for, and points towards important future research still to come.\n\nAmong these are e.g.\n\naugmented empirical data to identify causal factors behind diverse perceptions of GenAI use and patterns of adoption, barriers and scepticism across researchers of diverse backgrounds.\n\nSuch follow up is required to provide more in-depth evidence-based interpretability and recommendations for policy and support frameworks in academia.\n\nOwing to the fast development of GenAI and its many different ap- plications for research purposes, it is currently challenging to propose clear recommendations or guidelines for its usage.\n\nAny regulations proposed are likely to become obsolete quickly due to the speed of technological advancements.\n\nTherefore, we suggest following Knoechel et al.\n\n[27] approach in drafting principles that are flexible enough for implementation across various research fields.\n\nThis approach is also supported by our data, which indicates that regulations and guidelines have to take disciplinary differences (i.e.\n\ndifferences in knowledge production ways) into account to be effective.\n\nTo ensure successful integration, we suggest developing tailored strategies for diverse research contexts, working closely together with experts in those spe- cific fields.\n\nSuch a collaborative approach would ensure that strategies are tailored to the specific needs of the single research environments, thereby minimizing the risks of misalignment with the practices and experiences of individual researchers.\n\nLocal workshops, focus groups, and other collaborative activities could facilitate such a process, and it is recommended to involve the research community at large, including researchers as well as learned societies, funders, publishers, and uni- versity administrations.\n\nCRediT authorship contribution statement Jens Peter Andersen: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation, Software, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptu - alization.\n\nLise Degn: Writing \u2013 review & editing, Writing \u2013 original draft, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.\n\nRachel Fishberg: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.\n\nEbbe K.\n\nGraversen: Writing \u2013 review & editing, Writing \u2013 original draft, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.\n\nSerge P.J.M.\n\nHorbach: Writing \u2013 review & editing, Writing \u2013 original draft, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptu - alization.\n\nEvanthia Kalpazidou Schmidt: Writing \u2013 review & editing, Writing \u2013 original draft, Validation, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.\n\nJesper W.\n\nSchneider: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.\n\nMads P.\n\nS\u00f8rensen: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.\n\nEthics declaration The study obtained ethical approval from the Ethical Review Board of Aarhus BSS, Aarhus University, under document number: BSS-2023- 132.\n\nDeclaration of competing interest The authors declare no competing interests.\n\nAcknowledgements The authors would like to thank the 2534 respondents who completed the survey and the 533 respondents, who completed parts of it.\n\nWe would also like to thank student assistant, Simon Nielsen, from the Danish Centre for Studies in Research and Research Policy, Aarhus University, for his help with parts of the qualitative analysis, and PhD student Emil Dolmer Alnor for help extracting the participant informa - tion from university web pages.\n\nAppendix A.Supplementary data Supplementary data to this article can be found online at https://doi.\n\norg/10.1016/j.techsoc.2025.102813 .\n\nData availability Anonymised data is available at https://doi.org/10.17605/OSF.\n\nIO/6HTFS .\n\nReferences [1]H.\n\nBenbya, F.\n\nStrich, T.\n\nTamm, Navigating generative artificial intelligence promises and perils for knowledge and creative work, J.\n\nAssoc.\n\nInf.\n\nSyst.\n\nOnline 25 (1) (2024) 23\u201336, https://doi.org/10.17705/1jais.00861.\n\n[2]A.M.\n\nAl-Zahrani, The impact of generative AI tools on researchers and research: implications for academia in higher education, Innovat.\n\nEduc.\n\nTeach.\n\nInt.\n\n(2023) 1\u201315, https://doi.org/10.1080/14703297.2023.2271445.\n\n[3]R.\n\nPeres, M.\n\nSchreier, D.\n\nSchweidel, A.\n\nSorescu, On ChatGPT and beyond: how generative artificial intelligence may affect research, teaching, and practice, Int.\n\nJ.\n\nRes.\n\nMarket.\n\n40 (2) (2023) 269\u2013275, https://doi.org/10.1016/j.\n\nijresmar.2023.03.001.\n\n[4]A.\n\nKorinek, Generative AI for economic research: use cases and implications for economists, J.\n\nEcon.\n\nLit.\n\n61 (4) (2023) 1281\u20131317, https://doi.org/10.1257/ jel.20231736.\n\n[5]W.J.\n\nXie, A.\n\nWarshel, Harnessing generative AI to decode enzyme catalysis and evolution for enhanced engineering, Natl.\n\nSci.\n\nRev.\n\n10 (12) (2023), https://doi.\n\norg/10.1093/nsr/nwad331.\n\n[6]C.A.\n\nGao, F.M.\n\nHoward, N.S.\n\nMarkov, E.C.\n\nDyer, S.\n\nRamesh, Y.\n\nLuo, A.T.\n\nPearson, Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers, npj Digital Medicine 6 (1) (2023), https:// doi.org/10.1038/s41746-023-00819-6.\n\n[7]F.\n\nLarosa, S.\n\nHoyas, J.\n\nGarc\u00eda-Mart\u00ednez, J.A.\n\nConejero, F.\n\nFuso Nerini, R.\n\nVinuesa, Halting generative AI advancements may slow down progress in climate research, Nat.\n\nClim.\n\nChange 13 (6) (2023) 497\u2013499, https://doi.org/10.1038/s41558-023- 01686-5.J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 10 [8]A.\n\nBirhane, A.\n\nKasirzadeh, D.\n\nLeslie, S.\n\nWachter, Science in the age of large language models, Nature Reviews Physics 5 (5) (2023) 277\u2013280, https://doi.org/ 10.1038/s42254-023-00581-4.\n\n[9]H.\n\nElse, Abstracts written by ChatGPT fool scientists, Nature 613 (7944) (2023), https://doi.org/10.1038/d41586-023-00056-7, 423-423.\n\n[10] L.\n\nMesseri, M.J.\n\nCrockett, Artificial intelligence and illusions of understanding in scientific research, Nature 627 (8002) (2024) 49\u201358, https://doi.org/10.1038/ s41586-024-07146-0.\n\n[11] R.\n\nVan Noorden, J.M.\n\nPerkel, AI and science: what 1,600 researchers think, Nature 621 (7980) (2023) 672\u2013675, https://doi.org/10.1038/d41586-023-02980-0.\n\n[12] Committee on Publication Ethics, Authorship and AI tools.\n\nhttps://publicationeth ics.org/cope-position-statements/ai-author , 2024.\n\n[13] W.M.\n\nHepkema, S.P.J.M.\n\nHorbach, J.M.\n\nHoek, W.\n\nHalffman, Misidentified biomedical resources: journal guidelines are not a quick fix, Int.\n\nJ.\n\nCancer 150 (8) (2021) 1233\u20131243, https://doi.org/10.1002/ijc.33882.\n\n[14] T.\n\nPetricini, C.\n\nWu, S.T.\n\nZipf, Perceptions about generative AI and ChatGPT use by faculty and college students, Open Science Framework (2023), https://doi.org/ 10.35542/osf.io/jyma4.\n\n[15] C.\n\nShaw, L.\n\nYuan, D.\n\nBrennan, S.\n\nMartin, N.\n\nJanson, K.\n\nFox, G.\n\nBryant, GenAI in Higher Education \u2013 Fall 2023 Update, Turnitin, 2023.\n\nhttps://tytonpartners.co m/app/uploads/2023/10/GenAI-IN-HIGHER-EDUCATION-FALL-2023-UPDATE- TIME-FOR-CLASS-STUDY.pdf .\n\n[16] S.A.\n\nBin-Nashwan, M.\n\nSadallah, M.\n\nBouteraa, Use of ChatGPT in academia: academic integrity hangs in the balance, Technol.\n\nSoc.\n\n75 (2023), https://doi.org/ 10.1016/j.techsoc.2023.102370.\n\n[17] L.\n\nNordling, How ChatGPT is transforming the postdoc experience, Nature 622 (7983) (2023) 655\u2013657, https://doi.org/10.1038/d41586-023-03235-8.\n\n[18] B.\n\nOwens, How Nature readers are using ChatGPT, Nature 615 (7950) (2023), https://doi.org/10.1038/d41586-023-00500-8, 20-20.\n\n[19] R.\n\nWatermeyer, L.\n\nPhipps, D.\n\nLanclos, C.\n\nKnight, Generative AI and the automating of academia, Postdigital Science and Education 6 (2) (2023) 446\u2013466, https://doi.\n\norg/10.1007/s42438-023-00440-6.\n\n[20] European Commission, & European Research Council Executive Agency, Use and Impact of Artificial Intelligence in the Scientific Process \u2013 Foresight, P.\n\nO.\n\no.\n\nt.\n\nE.\n\nUnion, 2023 .\n\n[21] J.K.\n\nKim, M.\n\nChua, M.\n\nRickard, A.\n\nLorenzo, ChatGPT and large language model (LLM) chatbots: the current state of acceptability and a proposal for guidelines on utilization in academic medicine, J.\n\nPediatr.\n\nUrol.\n\n19 (5) (2023) 598\u2013604, https:// doi.org/10.1016/j.jpurol.2023.05.018.\n\n[22] A.\n\nGray, ChatGPT \"contamination\": estimating the prevalence of LLMs in the scholarly literature, arXiv (2024), https://doi.org/10.48550/arXiv.2403.16887.\n\n[23] Y.\n\nNing, S.\n\nTeixayavong, Y.\n\nShang, J.\n\nSavulescu, V.\n\nNagaraj, D.\n\nMiao, M.\n\nMertens, D.S.W.\n\nTing, J.C.L.\n\nOng, M.\n\nLiu, J.\n\nCao, M.\n\nDunn, R.\n\nVaughan, M.E.H.\n\nOng, J.J.- Y.\n\nSung, E.J.\n\nTopol, N.\n\nLiu, Generative artificial intelligence and ethical considerations in health care: a scoping review and ethics checklist, The Lancet Digital Health 6 (11) (2024) e848\u2013e856, https://doi.org/10.1016/s2589-7500(24) 00143-2.[24] M.\n\nHosseini, S.P.J.M.\n\nHorbach, K.\n\nHolmes, T.\n\nRoss-Hellauer, Open science at the generative AI turn: an exploratory analysis of challenges and opportunities, Open Science Framework (2024), https://doi.org/10.31235/osf.io/zns7g.\n\n[25] EU IPO, Navigating the complexities of generative AI in intellectual property: challenges and opportunities.\n\nhttps://www.euipo.europa.eu/en/news/navigatin g-the-complexities-of-generative-ai-in-intellectual-property-challenges-and-oppo rtunities , 2023.\n\n[26] P.\n\nHacker, A.\n\nEngel, M.\n\nMauer, Regulating ChatGPT and Other Large Generative AI Models 2023 ACM Conference on Fairness, Accountability, and Transparency, 2023 .\n\n[27] T.-D.\n\nKnoechel, K.\n\nSchweizer, O.A.\n\nAcar, A.M.\n\nAkil, A.H.\n\nAl-Hoorie, F.\n\nBuehler, M.\n\nElsherif, A.\n\nGiannini, E.\n\nHeyselaar, M.\n\nHosseini, V.\n\nIlangovan, M.\n\nKovacs, Z.\n\nLin, M.\n\nLiu, A.\n\nPeeters, D.\n\nvan Ravenzwaaij, M.A.\n\nVranka, Y.\n\nYamada, Y.-F.\n\nYang, B.\n\nAczel, Principles for responsible AI usage in research, Open Science Framework (2024), https://doi.org/10.31234/osf.io/g3m5f.\n\n[28] T.\n\nRavn, M.P.\n\nS\u00f8rensen, Exploring the gray area: similarities and differences in questionable research practices (QRPs) across main areas of research, Sci.\n\nEng.\n\nEthics 27 (4) (2021), https://doi.org/10.1007/s11948-021-00310-z.\n\n[29] M.\n\nHutson, Rules to keep AI in check: nations carve different paths for tech regulation, Nature 620 (7973) (2023) 260\u2013263, https://doi.org/10.1038/d41586- 023-02491-y.\n\n[30] S.v.\n\nBuuren, K.\n\nGroothuis-Oudshoorn, Mice: multivariate imputation by chained equations inR, J.\n\nStat.\n\nSoftware 45 (3) (2011), https://doi.org/10.18637/jss.v045.\n\ni03.\n\n[31] W.\n\nRevelle, Psych: Procedures for Psychological, Psychometric, and Personality Research, CRAN, 2024.\n\nVersion 2.4.6.26, https://cran.r-project.org/web/packag es/psych/index.html .\n\n[32] J.W.\n\nSchneider, N.\n\nAllum, J.P.\n\nAndersen, M.B.\n\nPetersen, E.B.\n\nMadsen, N.\n\nMejlgaard, R.\n\nZachariae, Is something rotten in the state of Denmark?\n\nCross-national evidence for widespread involvement but not systematic use of questionable research practices across all fields of research, PLoS One 19 (8) (2024), https://doi.org/ 10.1371/journal.pone.0304342.\n\n[33] W.\n\nWindelband, History and natural science, Theor.\n\nPsychol.\n\n8 (1) (2016) 5\u201322, https://doi.org/10.1177/0959354398081001 [1894]).\n\n[34] L.A.\n\nNogueira, J.O.\n\nRein, Chatbots: to cite or not to cite?\n\n(Part 1).\n\nThe Scholarly Kitchen, 2024.\n\nhttps://scholarlykitchen.sspnet.org/2024/06/19/chatbots-to-cite- or-not-to-cite-part-1/ .\n\n[35] S.P.J.M.\n\nHorbach, M.P.\n\nS\u00f8rensen, N.\n\nAllum, A.-K.\n\nReid, Disentangling the local context\u2014imagined communities and researchers\u2019 sense of belonging, Sci.\n\nPubl.\n\nPol.\n\n50 (4) (2023) 695\u2013706, https://doi.org/10.1093/scipol/scad017.\n\n[36] D.B.\n\nResnik, M.\n\nHosseini, The ethics of using artificial intelligence in scientific research: new guidance needed for a new tool, AI and Ethics (2024), https://doi.\n\norg/10.1007/s43681-024-00493-8.\n\n[37] J.W.\n\nSchneider, M.P.\n\nS\u00f8rensen, S.P.J.M.\n\nHorbach, J.P.\n\nAndersen, R.\n\nFishberg, E.\n\nK.\n\nGraversen, L.\n\nDegn, E.K.\n\nSchmidt, Research integrity AI survey, Open Science Framework (2024), https://doi.org/10.17605/OSF.IO/6HTF.J.P.\n\nAndersen et al.\n\nTechnology in Society 81 (2025) 102813 11",
    "metadata": {
      "type": "section",
      "title": "Abstract"
    }
  }
]